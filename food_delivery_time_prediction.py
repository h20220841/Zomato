# -*- coding: utf-8 -*-
"""Food Delivery Time Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZzzu4CQFBE5-EnMoFlnkrhqyxoVWmvz

## **Food Delivery Time Prediction using Machine Learning**
"""

#Import essential library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore')

#Upload and read the dataset
url = "https://raw.githubusercontent.com/h20220841/Zomato/main/Food%20Delivery%20time%20predictions/food_delivery.csv"

# Try reading the CSV with 'latin1' encoding
df = pd.read_csv(url, index_col=0, encoding='latin1')

df.head()

df.tail()

"""### 1.) **Data Preprocessing**"""

#Shape of the dataset
df.shape

"""Findings:

* data has 45593 rows and 10 columns
"""

df.columns

#Find any duplicate present in the dataset
df.duplicated().sum()

"""Findings:

* There are 12 duplicate rows are present in the data set. so we have to remove them from the dataset for further analysis.
"""

#Remove the duplicate columns
df_no_duplicates = df.drop_duplicates()

df_no_duplicates.duplicated().sum()

#Copy the no_duplicate data
data = df_no_duplicates.copy()
data.shape

#Is ther any null value present in the data?
data.isnull().sum()

"""Findings:

* There is no any null value is present in the dataset
"""

#Find out information about the dataset

data.info()

data.describe()

#Unique value in the data set
data.nunique()

#Check different data type data set
object_columns = data.select_dtypes(include='object').columns
print("object columns:")
print(object_columns)
print()
print("**********************************************************************************")
print()

numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns
print("Numerical columns:")
print(numerical_columns)

"""### Object Columns:

**Type of Order**
"""

#Deep dive into object type data set
data['Type_of_order'].unique()

data['Type_of_order'].value_counts()

#Draw the graph for better visualization
plt.figure(figsize=(10, 6))
sns.countplot(x=data['Type_of_order'], palette='hls')
plt.xticks(rotation=0)
plt.show()

"""Findings:

* From the above graph we can say that the heighest **type of order** is done for the **Snack** followed by **Drinks**
"""

#To see the contribution of different type of order
plt.figure(figsize=(15, 6))
counts = data['Type_of_order'].value_counts()
plt.pie(counts, labels=counts.index, autopct='%1.1f%%', colors=sns.color_palette('hls'))
plt.title('Type_of_order')
plt.show()

"""**Type of Vehicle**"""

data['Type_of_vehicle'].unique()

#Type of vehicle counts
data['Type_of_vehicle'].value_counts()

#Compare on the graph for better visualization
plt.figure(figsize=(16, 6))
sns.countplot(x=data['Type_of_vehicle'], palette='hls')
plt.xticks(rotation = 0)
plt.show()

"""Findings:

* Motorcycle vehicle is used more for the delivering the food followed by scooter and electric scooter
"""

#Plot on pie chart of type of vehicle is used
plt.figure(figsize=(15, 6))
counts = df['Type_of_vehicle'].value_counts()
plt.pie(counts, labels=counts.index, autopct='%1.1f%%', colors=sns.color_palette('hls'))
plt.title('Type_of_vehicle')
plt.show()

"""### Numerical Columns:"""

#Draw histogram of all data set of numerical data
for i in numerical_columns:
  plt.figure(figsize=(15, 6))
  sns.histplot(data[i], kde=True, bins=20, palette='hls')
  plt.xticks(rotation=0)
  plt.show()

#Draw Boxplot of all data set of numerical data
for i in numerical_columns:
  plt.figure(figsize=(15, 6))
  sns.boxplot(x=data[i],  palette='hls')
  plt.xticks(rotation=0)
  plt.show()

"""Findings:

* From the boxplot of Delivery person age, the minimum age is 15 and maximum age is 50 and median is 29.

* Delivering minimum rating is 1 and maximum is 6 and median is around 4.8
"""

#Draw histogram of all data set of numerical data
for i in numerical_columns:
  plt.figure(figsize=(15, 6))
  sns.violinplot(x=data[i], palette='hls')
  plt.xticks(rotation=90)
  plt.show()

#To see the effect of type of vehicle during the food delivery
for i in numerical_columns:
  plt.figure(figsize=(15, 6))
  sns.barplot(x = data['Type_of_vehicle'], y = data[i], ci = None, palette= 'hls')
  plt.show()

"""Findings:

* From the above we can see that the there is some effect of the rating  with bicycle vehicle. it may be due to the late delivering the food (as you can see the delivery time graph)
"""

#Let's see some of the other relationship between the numerical variables
for i in numerical_columns:
  for j in numerical_columns:
    if i != j:
      plt.figure(figsize=(15, 6))
      sns.lineplot(x = data[j], y = data[i], ci = None, palette='hls')
      plt.xticks(rotation = 90)
      plt.show()

#Finding the correlation between the variables
data_corr = data.corr()
data_corr

from numpy.matrixlib.defmatrix import matrix
# Draw the heat map of the correlation of the variable
plt.figure(figsize=(15, 6))
matrix = np.triu(data_corr)
sns.heatmap(data_corr, annot=True, linewidths=.8, mask=matrix, cmap="rocket")
plt.show()

#Extracting Time Components
data['hour_of_day'] = pd.to_datetime(data['Time_taken(min)'], unit='m').dt.hour
data['hour_of_week'] = pd.to_datetime(data['Time_taken(min)'], unit='m').dt.dayofweek
data['hour_of_year'] = pd.to_datetime(data['Time_taken(min)'], unit='m').dt.month

import math

# Function to calculate distance between two sets of latitude and longitude coordinates
def calculate_distance(lat1, lon1, lat2, lon2):
  R = 6371   # Earth's radius in kilometers

  # Convert latitude and longitude from degrees to radians
  lat1_rad = math.radians(lat1)
  lon1_rad = math.radians(lon1)
  lat2_rad = math.radians(lat2)
  lon2_rad = math.radians(lon2)

  # Haversine formula to calculate distance
  dlat = lat2_rad - lat1_rad
  dlon = lon2_rad - lon1_rad
  a = math.sin(dlat/2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2) ** 2
  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
  distance = R * c

  return distance

# Calculate distance and create the distance feature
data['distance'] = data.apply(lambda row: calculate_distance(row['Restaurant_latitude'], row['Restaurant_longitude'],
                                                             row['Delivery_location_latitude'], row['Delivery_location_longitude']), axis=1)

print(data['distance'])

# Categorizing Age data set
age_bins = [0, 30, 50, float('inf')]
age_labels = ['young', 'middle-aged', 'senior']
data['age_category'] = pd.cut(data['Delivery_person_Age'], bins=age_bins, labels=age_labels)

# Aggregating Ratings
data['avg_ratings'] = data.groupby('Delivery_person_ID')['Delivery_person_Ratings'].transform('mean')

# Binary Encoding
data = pd.get_dummies(data, columns=['Type_of_order', 'Type_of_vehicle'])

# Interaction Feature
data['time_ratings_interaction'] = data['Time_taken(min)'] * data['Delivery_person_Ratings']

data

# Remove 'ID' column as index columns
data.reset_index(inplace=True)

# Drop the columns that are not going to used for the ML used
columns_to_drop = ['ID', 'Delivery_person_ID', 'Restaurant_latitude', 'Restaurant_longitude',
                   'Delivery_location_latitude', 'Delivery_location_longitude']

# Drop the columns from the dataset
data = data.drop(columns=columns_to_drop)

data

data.info()

data.columns

# Import some of import library for modeling
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

# Group the data set into target and feature varibables
features_to_scale = ['Delivery_person_Age', 'Delivery_person_Ratings', 'time_ratings_interaction']
features_not_to_scale = ['Time_taken(min)', 'hour_of_day', 'distance',
                         'age_category', 'avg_ratings', 'Type_of_order_Buffet ', 'Type_of_order_Drinks ',
                         'Type_of_order_Meal ', 'Type_of_order_Snack ', 'Type_of_vehicle_bicycle ',
                         'Type_of_vehicle_electric_scooter ', 'Type_of_vehicle_motorcycle ',
                         'Type_of_vehicle_scooter ']
target = 'Time_taken(min)'

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(data[features_to_scale + features_not_to_scale], data[target], test_size=0.25, random_state=42)

# Perform feature scaling for the appropriate features
scaler = StandardScaler()
x_train_scaled = x_train.copy()
x_test_scaled = x_test.copy()
x_train_scaled[features_to_scale] = scaler.fit_transform(x_train_scaled[features_to_scale])
x_test_scaled[features_to_scale] = scaler.transform(x_test_scaled[features_to_scale])

# Performing one-hot encoding for the 'age_category' feature
ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), ['age_category'])], remainder='passthrough')

x_train_scaled = ct.fit_transform(x_train_scaled)
x_test_scaled = ct.transform(x_test_scaled)

"""### Model-1: Linear Regression"""

model_lr = LinearRegression()
model_lr.fit(x_train_scaled, y_train)

# Make prediction on the test data set
y_pred = model_lr.predict(x_test_scaled)

#Evaluate the model using root mean squared error (RMSE)
rmse = mean_squared_error(y_test, y_pred, squared=False)
print('Root Mean Squared Error:', rmse)

from sklearn.metrics import r2_score

# Calculate R-squared score
r2_lr = r2_score(y_test, y_pred)
print('R-squared Score:', r2_lr)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)
print('Mean Squared Error:', mse)

"""### Model_2: Decision Tree"""

from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

# Create and train the Decision Tree Regressor
dt_regressor = DecisionTreeRegressor(random_state=42)
dt_regressor.fit(x_train_scaled, y_train)

# Make predictions on the test set using Decision Tree Regressor
y_pred_dt = dt_regressor.predict(x_test_scaled)

# Calculate R-squared score for Decision Tree Regressor
r2_dt = r2_score(y_test, y_pred_dt)
print('Decision Tree Regressor - R-squared score:', r2_dt)

# Calculate Mean Squared Error (MSE) for Decision Tree Regressor
mse_dt = mean_squared_error(y_test, y_pred_dt)
print('Decision Tree Regressor - Mean Squared Error:', mse_dt)

# Create and train the XGBoost Regressor
xgb_regressor = XGBRegressor(random_state=42)
xgb_regressor.fit(x_train_scaled, y_train)

# Make predictions on the test set using XGBoost Regressor
y_pred_xgb = xgb_regressor.predict(x_test_scaled)

# Calculate R-squared score for XGBoost Regressor
r2_xgb = r2_score(y_test, y_pred_xgb)
print('XGBoost Regressor - R-squared Score:', r2_xgb)

# Calculate Mean Squared Error (MSE) for XGBoost Regressor
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print('XGBoost Regressor - Mean Squared Error:', mse_xgb)

